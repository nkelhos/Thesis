\cleartooddpage[\thispagestyle{empty}]
\chapter{Gamma Ray Reconstruction}\label{ch:grrecon}

In chapter \ref{chapter:veritas}, it was explained how the trigger system initializes the readout of PMT voltage traces.
To reconstruct gamma rays, the voltage traces induced by Cherenkov photons must be identified and combined to form an image of the original Cherenkov shower.
Then the shower images from multiple telescopes can be used to reconstruct the original gamma ray's energy and direction.

\section{Pedestal Variation}
  Before reconstructing any events, the pedestal and pedestal variations must be calculated.
  These is done by artificially triggering all pixels once per second during observations, in order to record events that contain only noise.
  The average of the digital counts (dc) of all noise-events for each pixel is then the pedestal.
  From this pedestal, the pedestal variations are then calculated for each pixel as the rms of all the dc counts in all noise-events, which can be visualized as the distribution of dc around the mean dc.
  In this context, noise-events can be due to night-sky-background photons, or from electronic noise.

\section{Pixel Identification}
  The first step is to determine which pixels are part of a shower image.
  This is done by subtracting the digital counts pedestal from the entire trace, and then integrating {\color{red} here you should mention the integration length.  Otherwise the second part will be unclear -Gernot??} the total dc in each voltage trace.

  Most voltage traces have the same general shape: a quickly rising start of the pulse, followed by a longer, slowly falling tail.
  To act as a point of reference in each voltage pulse, the time when the voltage trace is at half of its maximum value is called $T_{0}$.
  The trace is then integrated a second time using a smaller \SI{14}{ns} or \SI{24}{ns} wide time window, starting at $T_0$ - 30\%, to reduce the inclusion of dc from NSB photons and electronic noise.
  This two-pass algorithm is usually referred to as the double-pass method \cite{doublepass}.
  If a pixel's second-pass total dc is higher than 5 times the pedestal variation, then it is considered an image pixel.
  If it is between 2.5 and 5 times the pedestal variation, it is considered a border pixel.

  Once all pixels have been classified, isolated border pixels that have no neighboring image pixel are removed from the image, as they are more likely to be due to noise than Cherenkov photons.
  Then, the time gradient from the image and border pixels can be found by performing a linear fit of the $T_{0}$ times.
  This time gradient can then be used to place a third integration window {\color{red} Wrong, this is actually the second integration only.  Please correct also the paragraph above -Gernot?? Not sure I understand, there are 3 integration windows} with 30\% of the window before each pixel's $T_{0}$, to more accurately measure the charge due to Cherenkov photons in the pixel.
  {\color{red} i'm not sure, but isn't this the second integration pass what defines the 'double-pass' method?? -Orel}

  From the image pixels, border pixels, and time gradient, the shower's Hillas parameters \cite{hillas_params} can be calculated.
  These include the size of the shower in photoelectrons (or equivalent units), the shower center of charge, angle, length and width.
  The center of charge is the charge-weighted average of all image and border pixel positions.
  The angle of the shower determines how the image's major axis is oriented in the camera.
  The shower length and width are determined by the rms of the shower image along its major and minor axes, respectively.

\section{Position Reconstruction}\label{subsec:posrecon}
  By examining the images from multiple telescopes, the initial position of the event can be determined.
  This is done by overlapping all telescope images in a single camera coordinate system, and projecting each image's major axis backwards in time.
  These drawn lines should intersect very close together, and the average of the intersection points determines the event's initial direction.

  In averaging the intersection points, weighting for each intersection can be applied based on the angle between the two lines.
  This improves the reconstruction, because the intersection point from two images at \ang{90} angles will be less sensitive to image fluctuations than two images at \ang{160}, as shown in Figure \ref{fig:largeintersectangle}.
  Additionally, the disp method described in section \ref{subsec:disp} can be utilized to offer improvements at lower telescope elevations.

  \begin{figure}[ht]
    \centering
    \includegraphics[width=0.95\textwidth]{images/large_angle_image_intersection_error_cropped.eps}
    \caption[Large Image Intersection Angles]{
      In diagram (a), when a noisy pixel is added to an image, the reconstructed position is only moved a small distance (the purple arrow).
      In diagram (b), due to the large angle between images, the error in the reconstructed position is much larger.
    }
    \label{fig:largeintersectangle}
  \end{figure}
  \FloatBarrier

  \subsection{Angular Reconstruction with Boosted Decision Trees}\label{subsec:disp}
    At high elevations, shower images often form small intesection angles, because the telescopes are spread out in two dimensions, relative to the shower in the atmosphere.
    At low elevations near the galactic center, however, the telescope array flattens into one dimension, which makes the shower's impact parameter (the shortest distance between the telescope and the shower core axis) smaller for two of the telescopes.
    These two closer telescopes then have very short, almost circular images, which increases the sensitivity of those two image axes to noisy pixels or shower fluctuations, as shown in Figure \ref{fig:showerhighlowelev}.
    This also causes the remaining telescope images to have large intersection angles, which also reduces the accuracy of the position reconstruction.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.75\textwidth]{images/high_elevation_vs_low_shower_images_cropped.eps}
      \caption[Shower Images at High and Low Elevations]{
        In Figure (a), high elevation showers produce long images in all four telescopes.
        In Figure (b), lower elevation showers produce shortened images in two telescopes, and the remaining images form large angle intersection.
      }
      \label{fig:showerhighlowelev}
    \end{figure}

    To better handle these near-parallel image axes at low elevations, the reconstructed position can be determined from more parameters than just the weighted image axes intersection points.
    From simulations, the distance between the center of the Hillas shower image and the true position can be calculated, where the angular distance between the two is the \disp{} parameter\cite{Senturk:2011}, shown in Figure \ref{fig:dispdiagram}.
    Then, this \disp{} parameter can be provided to a machine learning algorithm \cite{Beilicke2012NIM}, along with other image parameters like:
    \begin{description}
      \item[\textit{width}:] image angular width
      \item[\textit{length}:] image angular length
      \item[\textit{wol}:] $\frac{\textrm{width}}{\textrm{length}}$
      \item[\textit{size}:] total image dc
      \item[\textit{ntubes}:] number of pixels in the image
      \item[\textit{loss}:] fraction of image pixels at the edge of the camera
      \item[\textit{asym}:] distance between image center-of-dc and the pixel with the highest dc
      \item[\textit{tgrad}:] the slope of the linear time fit to the pixel arrival times
      \item[\textit{cross}:] angular distance between the image center and the average intersection point of the image axes.
    \end{description}
  % list of training parameters: grep "AddVariable" $EVNDISPSYS/src/trainTMVAforAngularReconstruction.cpp
  % how variables are calculated: grep -P "fParGeo.+\=" $EVNDISPSYS/src/VImageParameterCalculation.cpp
  % asym: http://inspirehep.net/record/1395717/files/RdelosReyes.pdf
  % Once trained on these parameters, the machine learning algorithm can construct a boosted decision tree for determining any new image's \textit{disp}, which can then be used with the image axes intersections to improve the gamma-ray reconstructed positions.


    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.5\textwidth]{images/disp_parameter_cropped.eps}
      \caption[Angular Reconstruction Disp]{
        The \disp{} parameter is the angular distance between the center (red dot) of a hillas image (blue oval) and the true sky position (green dot).
        Generally, longer shower images have a larger \disp{} angle.
      }
      \label{fig:dispdiagram}
    \end{figure}

    % https://veritas.sao.arizona.edu/wiki/index.php/BDT_Angular_reconstruction
    These parameters for thousands of simulated showers can then be used to train boosted decision trees (BDTs) that estimate the \disp{} for a new shower's images.
    This estimated \disp{} can then be used with the image axes intersection points to more accurately reconstruct the original gamma-ray point of origin.
    
    Once the training is complete, it is tested on a separate set of 17,000 simulated events, which have their true and predicted \disp{}s plotted in Figure \ref{fig:disptraining}.
    The x axis describes the true \disp{} value for each event, while the y axis describes the \disp{} value estimated by the BDT, with a black $x=y$ line marked, which represents a perfect 1:1 \disp{} reconstruction.
    As events fall on the $x=y$ line, it can be concluded that the BDTs are able to predict the correct \disp{} value for most images.
    {\color{red} You need to be more precise.  You should show also a one dimenional distribution (or various if you want to divide to True DISP bins) and discuss the resolution obtained?? -Orel}

    % made from screenshot of last slide in Dropbox/Presentations/20160719_Group_Meeting.key
    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.85\textwidth]{images/disp_training.eps}
      \caption[Disp BDT Training]{
        The true \disp{} vs the BDT-predicted \disp{}, for \nicetilde17,000 gamma-ray event images in T1, from \SI{500}{\GeV} to \SI{200}{\TeV}.
        {\color{red}'disp' in the plot labels/title should be italics, like in the text??}
      }
      \label{fig:disptraining}
    \end{figure}
    
    {\color{red} profile plot of the true/BDT disp vs true disp, with 68\% containment errorbars, and talk about it in the text! is there a bias? at what disps? }

    The small improvement in the position reconstruction due to the \disp{} method can be seen in Figure \ref{fig:disp_event_offset}.
    With the Geometric (red) events, more are concentrated further from the point source, while with the Disp method, somewhat more are concentrated at the source itself.
    
    {\color{red}Again, you need to be more specific. First, it is important to note this is data, it’s always good to “brag” that your reconstruction method is tested on data.  Second, you need to discuss the actual resolution obtained with both methods and state the improvement achieved with DISP. I think the RMS might be a better test of this and anyway the mean would be too affected by the tail. In fact I think the quantiles are better?? -Orel}
    
    {\color{red} Mention that from here on in the analysis, the disp method is used! ??}
  
    {\color{red}I don't understand why the improvements are so small.  Different ot what I see. -Gernot?? }

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.85\textwidth]{images/disp_event_offset_hists/dispgeom_comparison.eps}
      \caption[DISP Offset Improvement]{
        The fraction of events at different angular offsets from the Crab and the Galactic Center per solid angle, with Geometric (intersection only) and Disp reconstruction methods.
        Data elevations are the same as in Figure \ref{fig:datapointingelevations}, while training events were simulated at only 28\degree{}.
        {\color{red}(Where is the disp improvement???)}
        {\color{red}(Why is the containment radius worse for disp??)}
        {\color{red}(Redo disp training with 5x events! ??)}
      }
      \label{fig:disp_event_offset}
    \end{figure}
  
  \FloatBarrier

\section{Energy Reconstruction}\label{subsec:enrecon}
  To reconstruct the energy of each shower, a lookup table of simulated showers is built.
This database includes the width and length of the shower, how far away its core position is, how bright it was, as well as its reconstructed and true energy.
  By scanning through this database for showers that are similar to the one being constructed, the most similar-looking shower then indicates the true energy {\color{red} (is there any interpolation?? -Orel?? ask gernot)}.


\section{FITS Conversion for Gammalib and CTOOLs}\label{fitsconversion}
  Once gamma rays have been reconstructed with Eventdisplay, they must be converted to a FITS file format compatible with Gammalib and CTOOLS.
  This format consists of a FITS file with an event list table, containing each gamma ray, its energy, sky direction, and time.
  This also includes meta information about the event list like the telescope's pointing target and the start and end times of the event list.
  This FITS file can then be read into Gammalib and CTOOLS \cite{gammalibctools}.

  In addition to the event list, the instrument response functions (IRFs) must also be imported into Gammalib and CTOOLS.
  These IRFs consist of the effective areas, the point spread functions, the background models, and the energy dispersion.
  The effective area quantifies the total gamma-ray collection area of the observatory, needed for spectral measurements, and is described in subsection \ref{subsec:effarea}.
  The point spread function (sometimes referred to as psf) quantifies the distribution of true positions for a reconstructed position {\color{red}Isn't it the other way around?? -Orel}, which is needed for identifying point sources and extended spatial structures.
  This is described further in Subsection \ref{subsec:psf}.
  The background models measure the relative number of observed events in different parts of the camera, and their construction is described in subsection \ref{background_production}.
  The energy dispersion quantifies the distribution of true energies for a given reconstructed energy {\color{red}Is this the right way around?? -orel}, and is discussed in subsection \ref{subsec:edisp}.

  Each of these IRFs vary in a parameter space with several dimensions, including event Energy, reconstructed distance from the camera center, telescope elevation and azimuth, and night sky background noise.
  In CTOOLS' default configuration, all IRFs are stored in a single directory of files, and each event list contains a filepath reference to indicate which volume of the parameter space it uses.
  Once each volume is loaded, individual events can then interpolate their specific effective area, psf, and energy dispersion (the backgrounds are utilized differently, as discussed in subsection \ref{background_production}).
  {\color{red}All of this information from 5.5 to 5.5.1 on data format and dividing runs to smaller chunks etc. has to be rewritten from the physical point of view and all of the computational references should be removed. I know it sounds weird, but the computational details are of no interest. What’s important is the fact you divided your data into smaller bins in order to avoid large changes within each bin.  We can discuss this of course. -Orel??}

  However, the galactic center is at an elevation of \ang{30}, much lower than most VERITAS observation targets.
  At this elevation, with its field of view of \ang{3.5}, the airmass column density ($g/cm^{2}$) is 20\% higher at the bottom of the camera than at the top.
  Add to this that during a single 30 minute observation, the elevation of the Galactic Center can change by several degrees.
  This means the airmass in view of the camera may change rapidly, resulting in IRFs that are time dependent.

  To allow for the inclusion of this time dependence in the analysis, observing runs were broken up into smaller time chunks, and each time chunk had IRFs assigned to each chunk based on that chunk's position in the elevation/azimuth/night-sky-background-noise parameter space.
  There were minor issues with converting the IRFs that are noted in the following sections.

  \FloatBarrier
  
  \subsection{Effective Area}\label{subsec:effarea}
    % use effective area as a casual noun!
    % plot of effective area vs energy
    Effective area is the measure of how large an observatory's collection area is, determining how many gamma rays can be detected per unit time, solid angle, and energy.

    For each point in the parameter space, the effective areas are calculated with many {\color{red}(how many?? -Gernot (probably # corsika showers * number of core rescatters * # camera repositions))} Monte Carlo gamma ray simulations.
    This is done in the shower plane, {\color{red} the plane perpendicular to the line drawn between an observing source, and the center (shower plane depends only on the pointing direction, not on what source is observed -Gernot??)}of the observatory.
    The effective area is then calculated via:
    $A=\pi R^2 \frac{N_{\text{survived}}}{N_{\text{simulated}}}$
    where R is the radius of the area within which simulated showers are directed to fall, $N_{\text{simulated}}$ is the number of showers that were initially simulated into the area, and $N_{\text{survived}}$ is the number of simulated showers that pass all cuts.
    This effective area is thus a measure of how much detection area the observatory would have if it had a 100\% detection efficiency, which can then be used in calculating a source's flux.
    In Figure \ref{fig:effarea_paramspace}, it can be seen how the effective area peaks to \nicetilde{}\SI{3e5}{m${}^2$} for \SI{3}{\TeV} events at the camera center.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.85\textwidth]{images/effarea_plots/effarea_space.eps}
      \caption[Effective Area Parameter Space]{
        Effective areas at different points in the Energy and Camera Offset parameter space for run 78128.
        Data is shown as the black points, indicating the position of some events from that run in the parameter space.
        The color axis indicates the Effective Area, calculated from simulations, at different gamma-ray energies and distances from the camera center.
      }
      \label{fig:effarea_paramspace}
    \end{figure}

    For the test analyses of the Crab Nebula and the Galactic Center Point Source, the effective areas of all events are shown in Figure \ref{fig:effarea_usage}.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.85\textwidth]{images/effarea_plots/effarea_events.eps}
      \caption[Effective Areas Used]{
      Illustration of the effective areas used by all events in each analysis.
      From these plots, it is easy to check for events with anomalously high (>\SI{400000}{m${}^2$}) or low (\nicetilde\SI{0}{m${}^2$}) effective areas.
      }
      \label{fig:effarea_usage}
    \end{figure}
  
  \FloatBarrier

  \subsection{Point Spread Function}\label{subsec:psf}

    When reconstructing the source position of each gamma ray, it is necessary to know the uncertainty of the position.
    Primarily, errors in the position come from the randomness of shower images.
    The same gamma ray may develop differently due to several causes.
    Differences may be due to different particles early in the shower gaining different amounts of energy, or particles scattering at different angles.
    In addition, different Cherenkov photons may be absorbed by the atmosphere, or reflected by the mirrors, or converted into PMT photoelectrons.
    In the image and position reconstruction, this means that an initial gamma ray can develop into a distribution of camera images, and vice versa, that a single shower image can come from a distribution of gamma ray positions.

    This distribution of reconstructed positions, called the point spread function (psf), primarily affects the reconstructed shape of gamma-ray emission structures in the sky.
    A singular point source, nominally shaped by a Dirac function, is instead distributed out according to the psf.
    When searching for an extended source, like a dark matter halo, understanding the distribution of reconstructed positions is important.
    A large psf on all events, for instance, will artificially expand the observed dark matter halo.

    For VERITAS, the psf is estimated by simulating many gamma rays, then measuring the distribution of true positions for each reconstructed position.
    The distribution of event positions are fitted with a King function \cite{king1962} (see eqn \ref{eqn:king}), as the H.E.S.S. collaboration has noted that the King function better models the longer PSF tails at lower elevations (Section 5.2.2 in \cite{Mayer2015}).
    The radially-normalized King probability density function is defined as

    \begin{equation} \label{eqn:king}
    \text{psf}_{king}(r) = \frac{1}{2 \pi \sigma^{2} } \left( 1 - \frac{1}{\gamma} \right) \left( 1 + \frac{ r^{2} }{ 2 \gamma \sigma^{2} } \right)^{-\gamma}
    \end{equation}

    where $r$ is the angular distance from the reconstructed position, $\sigma$ is similar to the width of a gaussian, and $\gamma$ governs how long the tails are.
    A King function fitting algorithm was added to Eventdisplay, that fits the $\gamma$ and $\sigma$ parameters to a set of simulated gamma rays.
    This leads to good fits over almost all of the parameter space.
    In Figure \ref{fig:psf_paramspace}, the psf is shown for one Sgr A* run.
    In it, one can see how the psf containment radius changes vs reconstructed energy and offset from the camera's center.
    Other runs, which have different elevations, azimuths and NSB noise levels will have different values at each point in the energy/offset parameter space.

    % plot of psfs from chunkplot
    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.85\textwidth]{images/psf_king_plots/psf_parameter_space.eps}
      \caption[PSF Parameter Space]{
        The 68\% containment radius for the Energy/Offset parameter space for Sgr A* run 78128. 
        The green points are from data, showing a subset of the event locations from run 78128 in the parameter space.
        The color axis is the containment radius, calculated from simulations.
        While events from all energies are shown, only events from \SI{4}{\TeV} - \SI{70}{\TeV} are used (see Section \ref{subsec:crab_analysis}).
      }
      \label{fig:psf_paramspace}
    \end{figure}

    For the Galactic Center and the Crab analyses, the distribution of 68\% containment radii for all events is shown in Figure \ref{fig:gc_psf_hist}.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.85\textwidth]{images/psf_gc_eventhist/eventpsf.eps}
      \caption[Crab and Galactic Center Event PSFs]{
        The 68\% containment radius for all Galactic Center and Crab Nebula events used in this analysis.
        {\color{red}why the long tail?? Large offset and low energy data?? -Gernot}
        {\color{red}You need to explain in the text any non-trivial features in the plots. That is, you need to say what is the resolution observed and explain what is the second peak seen in the Galactic centre data. ?? -Orel}
        {\color{red}Crab -> Crab Nebula ??}
      }
      \label{fig:gc_psf_hist}
    \end{figure}
  
  \FloatBarrier
  
  \subsection{Background Models}\label{background_production}
  
    A background model is a 3 dimensional function in camera x (in angle, parallel to azimuth), camera y (in angle, parallel to elevation), and energy.
    Each background model is constructed from one of two templates, and the templates are built from dark run observations (see Figure \ref{fig:gcfieldsofview}).
    These background models calculate the number of expected events in the camera, per unit solid angle, unit time, and unit energy.
    This is used to quantify how many counts are expected in different parts of the camera when observing any target.
    Understanding the background shape of the camera is crucial for properly studying extended sources, like dark matter halos, which may extend several degrees from the galactic center.
    Improperly estimating background models can result in fake structures appearing around an astrophysical target.
    Background models with more than three dimensions are also possible, but require many more simulations, and are beyond the scope of this thesis.
    
    The background models used in this analysis are made from two background templates, one for each of the V5/V6 epochs (see Section \ref{sec:epochs}).
    The templates are constructed from dark observations, detailed in \ref{veritasdata}.
    Each template is made by histogramming all background events by their energy, dividing by the bin width, and interpolating between bins to produce a spectral function.
    This spectral function can be seen in Figure \ref{fig:background_profile}.
    
    {\color{red}These two paragraphs can be shortened to one short one with less details. Just mention the binning radially and in energy. The technical way it is done is of less interest. ?? -Orel}

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.65\textwidth]{images/ctools_background/background_construction.eps}
      \caption[CTOOLS Background Fine Energy Bins]{
        The V5 Background's fine-energy bins.
        The top plot shows the number of events in each fine-energy bin.
        The bottom plot shows the CTOOLS background values.
        The black lines show the fits background value and energy bin width saved to the background file, while the blue line shows the background value after CTOOLS loads and interpolates those fits background values.
        {\color{red}Please do not mention it as CTOOLS. Rather, write it in “physics language”, fit, background rate, etc. ?? -Orel}
      }
      \label{fig:background_profile}
    \end{figure}

    Then, the events are divided into high and low energies, and the events' reconstructed camera positions are binned radially about the camera center, with each bin divided by its bin area, producing two spatial functions.
    These high- and low-energy spatial functions are shown in Figure \ref{fig:background_radial}.
    {\color{red}(tweak hyperref plugin to make links a different color??)}
    
    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.65\textwidth]{images/ctools_background/radial_profiles.eps}
      \caption[CTOOLS Radial Background Profiles]{
        Radial bin profiles for the V5 background's two large-scale energy bins.
        The blue points are the counts per bin area, while the purple line is a spline interpolation with a 3rd order polynomial.
        {\color{red}You need to explain in the text the feature seen in both plots, the plateau and small peak at about 1 degrees. ?? -orel}
        }
      \label{fig:background_radial}
    \end{figure}
    
    Finally, the spatial and spectral functions are multiplied together, as in Equation \ref{eqn:bck_template}.
    
    \begin{equation}\label{eqn:bck_template}
      f(e,x,y) = A \times \textrm{spectral}(e) \times \textrm{spatial}(e,x,y) 
    \end{equation} 
    
    The function $f(e,x,a)$ has units of $\frac{\# Counts}{ \textrm{MeV} \times \textrm{s} \times \textrm{sr} }$.
    The multiplied functions are then scaled with a constant $A$ such that the total integral of the template (integrating across camera x, camera y, and Energy) is equal to the original number of counts in the dark runs, as in Equation \ref{eqn:background_template_function}.
    
    \begin{equation}\label{eqn:background_template_function}
      \textrm{\# Background Events} = A \times \int \textrm{spectral}(e) \times \textrm{spatial}(e,x,y) \times dx \: dy \: de
    \end{equation}

    This function $f(e,x,y)$ is the background template in camera x/y, which due to its radial symmetry can then immediatly be used as a CTOOLS background model in RA/Dec.
    Each background template is used in the likelihood analysis as a model multiplied by two free parameters, a normalization factor, and a the event energy exponentiated by the spectral index.
    This lets the likelihood fit scale each run's background model up or down to best fit the events, so the background's absolute value is less important than the relative values in different parts of the camera or at different energies.
  
  \FloatBarrier

  \subsection{Energy Dispersion}\label{subsec:edisp}
    As events are reconstructed imperfectly, it is important to understand what the distribution of true energies are for a given reconstructed energy.{\color{red}(Again, not sure, but perhaps the other way around?? -Orel)}{\color{red}(just remove all mentions of $f_{reco}$, its not necessary ??)}
    This \textit{dispersion in energy} is quantified by an energy migration matrix $E_{i,j}$, where $i$ denotes the $i^{\text{th}}$ reconstructed energy bin, and $j$ denotes the $j^{\text{th}}$ true energy bin.
    The energy migration matrix can be used to account for two significant effects.
    The first is that the reconstruction method introduces biases in the event energy, meaning on average, an event at a given true energy can be reconstructed at a higher or lower energy.
    The second effect that is accounted for is the dispersion in the reconstructed energies.
    Gamma rays with the same energy will have their energies reconstructed as a distribution close to the true energy.
    These fluctuations can be due to randomness in air shower development, atmospheric absorption of Cherenkov photons, 
    This has the effect of smearing out events in each energy bin of a spectra.
    In the gamma-ray spectra of astrophysical sources, which often follow a power law, lower energy bins tend to have more events than higher energy bins, so smearing out the lower-energy bin contributes more to the higher-energy bin than the higher-energy bin contributes to the lower-energy bin.
    This has the effect that, when not accounted for, energy dispersion will harden observed astrophysical source spectra.
    In Figure \ref{fig:migmatrix}, a migration matrix is shown.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.85\textwidth]{images/edisp_plots/edisp.eps}
      \caption[Energy Migration Matrix]{
        An energy migration matrix used with Sgr A* run 82288.
        The reconstructed energy is on the x axis, and the true energy is on the y axis.
        The z (color) axis denotes the number of simulated events that passed all cuts.

        {\color{red} (why does the z axis have units of 1/s*MeV?? GCTAEdisp2D::operator() returns these units, but why??)} 
      
        {\color{red}Most events are reconstructed off axis?? -Gernot}
        
        {\color{red}Need to explain downturn at lowest energies?? -Gernot}
        
        {\color{red}Again, please describe in the text non-trivial features in the plot (the bias at low energy) ?? -orel}
      }
      \label{fig:migmatrix}
    \end{figure}
  
  \FloatBarrier

\section{Camera Studies}
  The objective of this thesis is to put upper limits on the existance of a gamma-ray source that is both extended and faint.
  {\color{red}(That is not the objective of the analysis though. The objective is to search for dark matter, not to admit defeat from the get go and aim at setting an upper limit.?? -Orel) (This sounds like you've already admitted defeat before the analysis started, your object should be to find dark matter, win a nobel prize!??)}
  In order to better understand the effects that may impact the VERITAS camera behavior in the reconstruction method, several studies were performed.
  {\color{red} You should connect between these two sentences, “because it is extended and faint, the background has to be determined with high precisions, etc.” ?? -Orel}

  \subsection{Background Structure at the Low Energy Threshold}
    To produce background models, events were binned in energy, elevation, camera x, and camera y.
    As a result of this detailed binning, some new effects were noted.
    First, a series of gamma-like events were selected from observations with no known gamma-ray sources.
    These events were then divided into equal-statistics energy bins.
    For each bin, all the contained events were then binned in camera x and y.

    For a set of high-elevation observations, these backgrounds are shown in Figure \ref{fig:back_highelev}.
    It can be seen that all events are divided up into 3 equal-statistics energy bins in Figure \ref{fig:back_highelev}.A.
    Each energy bin is then binned in camera x and y in Figure \ref{fig:back_highelev} B, C, and D.
    At these high elevations, the distribution of events in each energy bin is radially symmetric about the camera center.
    This happens because gamma ray's point of origin and its shower image in the camera are usually several tenths of a degree away from each other.
    In addition, the atmospheric mass-depth is similar in all parts of the camera.
    However, structures start to break the radial symmetry at low energies and elevations.
    The cause of these structures is explored in the next section, \ref{subsubsec:diffusesims}.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=\textwidth]{images/ctools/backgrounds_highelev.eps}
      \caption[FITS Background at \ang{50} Elevation]{
        Gamma-like Events from 52 observations (approximately \nicetilde20 hours) of M82, between \ang{50} and \ang{52} elevations.
        Events in Figure A are divided into 3 equal-statistics energy bins, and binned in Camera Coordinates in Figures B, C, and D.
      }
      \label{fig:back_highelev}
    \end{figure}

    In Figure \ref{fig:back_lowelev29} and Figure \ref{fig:back_lowelev26}, the same plots are constructed for a set of low-elevation (\nicetilde{}\ang{29} and \nicetilde{}\ang{26} respectivly) observations, using dark observations (see Section \ref{background_production}, Figure \ref{fig:gcfieldsofview}, and Section \ref{sec:bkgmodels}) 
    It can be seen that in different energy bins, the background possesses different shapes.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=\textwidth]{images/ctools/backgrounds_lowelev29.eps}
      \caption[CTOOLS Background at \ang{29} Elevation]{
        15 Sagittarius A* Off runs (\nicetilde7.5 observation hours), between elevations $ \ang{27.5} $ and $ \ang{30} $.
        Events are divided into 6 equal-statistics energy bins, of which four are binned in Camera Coordinates in Figures B, C, D, and E.
      }
      \label{fig:back_lowelev29}
    \end{figure}

    \begin{figure}[ht]
      \centering
      \includegraphics[width=\textwidth]{images/ctools/backgrounds_lowelev26.eps}
      \caption[CTOOLS Background at \ang{26} Elevation]{
        10 Sagittarius A* Off runs (\nicetilde5 observation hours), between elevations \ang{24} and \ang{27.5}. 
      }
      \label{fig:back_lowelev26}
    \end{figure}
  
  These effects are also noticeable in the galactic (l,b) event maps.
  In Figure \ref{fig:bkgvsel_crab}, the top plot shows the positions of all events, the middle histogram shows the distribution of event energies, and the bottom plot shows the event positions of events in a limited energy range, \SI{1.5}{\TeV}-\SI{3.25}{\TeV}.
  It can be seen in the middle plot that this energy range is where more and more events are lost as energy decreases.
  When events are plotted in this limited energy range, it can be seen that there is a faint deficit along the bottom of the camera.
  Due to the time-dependent rotation between camera x/y coordinates and sky (RA/Dec) coordinates, this deficit occurs in the bottom of the camera, where the atmosphere column density ($g/cm^2$) is \nicetilde20\% higher than at the top of the camera.
  This \nicetilde20\% higher airmass causes air showers to start further away from the telescopes and absorbes more Cherenkov photons, resulting in fewer events being detectable in the lower half of the camera.

  When a similar series of plots are made for the galactic center in Figure \ref{fig:bkgvsel_sgra}, the effect is much stronger.
  In the top plot, events are radially symmetric about the source (there are differences due to the four wobble positions, but these are faint and not visible without quantification).
  But when only the events from \SI{1.5}{\TeV} to \SI{3.25}{\TeV} are plotted, a much clearer deficit is visible on the lower right part of the plot.
  This area corresponds to the deficit at bottom of the camera in Figures \ref{fig:back_lowelev29}.B and \ref{fig:back_lowelev26}.B
  It should be noted that there is a time-dependent rotation applied to go from the camera x/y (Earth Azimuth/Elevation) system to the Galactic (l,b) coordinates, which smears out the shape of the deficit, making it harder to notice in sky coordinates.
  
  This effect is important to this analysis because it implies that, at the lowest energies, the background rate is not radially symmetric.
  Radial backgrounds (sometimes referred to as acceptances) are typically used in VERITAS as no other camera x/y or energy dependence had been demonstrated until now.
  As the analysis in this thesis only has a few hours of background observations (see table \ref{tab:observation_times}), only radially symmetric backgrounds templates/models could be constructed, which then required limiting the final analysis to $\geq\SI{4}{\TeV}$.
  
  \begin{figure}[ht]
    \centering
    \includegraphics[height=0.9\textheight]{images/background_vs_elevation/background_vs_elevation_srccrab.eps}
    \caption[Background Vs Elevation Crab]
    {\small 
      Plots of Crab Nebula observations.
      Top: Skymap of all events.
      Middle: Histogram of all events in energy.
      Bottom: Skymap of events from \SI{1.5}{\TeV}-\SI{3.25}{\TeV}.  
      The blue circles, centered on the Crab Nebula, are to help highlight the radial symmetry of the top plot, and the lack of radial symmetry in the bottom plot.
      {\color{red}Crab->Crab Nebula !??}
    }
    \label{fig:bkgvsel_crab}
  \end{figure}

  \begin{figure}[ht]
    \centering
    \includegraphics[height=0.9\textheight]{images/background_vs_elevation/background_vs_elevation_srcsgra.eps}
    \caption[Background Vs Elevation Sgr A*]
    {\small 
      Plots of Sgr A* observations.
      Top: Skymap of all events.
      Middle: Histogram of all events in energy.
      Bottom: Skymap of events from \SI{1.5}{\TeV}-\SI{3.25}{\TeV}.  
      The blue circles, centered on the Galact Center, are to help highlight the radial symmetry of the top plot, and the lack of radial symmetry in the bottom plot.
    }
    \label{fig:bkgvsel_sgra}
  \end{figure}
  
  \FloatBarrier

  \subsection{Diffuse Simulations}\label{subsubsec:diffusesims}
    Diffuse simulations were performed at similar energies and elevations to see if this effect was still present.
    These consisted of simulating 50,000 gamma rays with CORSIKA (\cite{corsika1998}) at each of 1.4, 1.6, 2, and \SI{5}{\TeV}.
    The telescopes were fixed to an azimuth/elevation of (\ang{193}, \ang{28}).
    The events themselves were distributed in a diffuse \ang{2.5}-radius disk.
    To approximate a simple gamma-hadron cut, any events with a mean-scaled-width falling outside the range of -2.0 to 0.5 were removed, which eliminates many of the showers that appear proton-like.
    These remaining 'gamma-like' events are then binned in camera coordinates in Figure \ref{fig:back_simdiffuse}.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=\textwidth]{images/backgrounds_diffuse_vs_data/backgrounds_sims/backgrounds_sims.eps}
      \caption[Diffuse Simulated Backgrounds]{
        Diffuse simulated gamma-like events in the camera coordinate system at a \ang{28} elevation, at 4 different initial energies.
        {\color{red}What does the True camera position look like for these events??}
      }
      \label{fig:back_simdiffuse}
    \end{figure}

    One can see that the ring and crescent structures persist in these diffuse simulations, implying these are physical effects of the atmosphere and camera, rather than a problem with the reconstruction method.
    {\color{red}(But what is the effect? I remember Gernot mentioning something about an edge effect? You should explain it here. --Orel??)}
    {\color{red}(The top-of-camera vs bottom-of-camera differences are due to the atmosphere, but I'm not sure what causes the deficit in the middle at the lower energies... ??)}
    {\color{red}(I am not sure what is the reason for the deficit in the middle. Are simulations always with a wobble? Maybe the showers are very small and always at some distance from the centre of the camera?? -Orel)}
    {\color{red}(Consider playing with the distribution of disps and the radial areas??)}

    This striking effect can be seen in Galactic Center data between certain energy ranges.
    As the plots are in galactic (l,b) coordinates, and there is a time rotation due to the Earth spinning on its axis, and observations are made at four wobble positions, the events clearly favor one half of the camera.
    
    These structures, and their strong dependency on both the energy and elevation of the telescopes may be a large factor in why the low-energy threshold regime of gamma-ray telescopes is poorly understood.
    Incorporating this effect into the instrument response functions would require modifying Eventdisplay and CTOOLS, as well as creating another batch of diffuse simulations, with elevation increments of less than \ang{5}, all of which are computationally expensive.
    {\color{red}It is good to explain that this is a global issue and even suggest how it can be fixed generally for VERITAS, but do not mention the software packages or computationally expensive. Instead, write something like “background templates are needed for the different bins” and that it is beyond the scope of this analysis (or that it was not performed due to time constraints). ?? -Orel}
    {\color{red}(Since there isn't enough background runs to make properly elevation and energy dependent background models (see significance skymap in chapter 6), This should be phrased as "More data is needed to properly populate the increased number of bins." ??)}
  
  \FloatBarrier

  \subsection{Effect of Stars}
    As understanding the camera's background is important for extended source studies, i.e. dark matter halos, studies were performed examining the spatial effects of stars in the camera.
    It had been noted in the past that for visual magnitude \nicetilde{}6-8 stars, the camera pixels they illuminated would have a higher average current.
    This translated into a higher pedestal variation in the affected pixels, which decreased how often the pixel participated in shower images.
    In addition, if a star with magnitude brighter than 6 was in the field of view, it would cause high enough current in the pixel that it's voltage would be set to zero to prevent it from being damaged.
    For particularly bright stars (magnitude $\leq{}3$), often several pixels are disabled at a given time.

    A third effect is that, since the telescope camera is fixed to the ground, from the camera coordinate system, the sky rotates around the camera center.
    This means that over a single 30 min observation, any stars rotate around the camera center, disabling several camera pixels as it passes over them.
    The camera checks for these disabled pixels roughly once per minute by turning their voltage back on and monitoring the current, and setting it back to zero if the current is still above the threshold.

    These effects imply that to study the effect of stars, one must study the effect of high-current and disabled camera pixels, and use this information to construct the effect of stars.
    In this section, the effects of disabled camera pixels are studied.
    
    {\color{red}Divide to sections here maybe? Not sure, maybe will help with the flow between introduction and analysis. ?? -Orel}

    % see calculations/disabledpixel_obstime , those 250 crab runs turned into about 13.5 observation hours
    To examine the effects of disabled pixels, \nicetidle13 hours of Crab observations were reconstructed twice.
    The first analysis was with the default analysis chain settings, and the second time with a single pixel disabled in all four telescopes.
    This mimics the effect of having a star in the field of view that is bright enough to disable a pixel.

    After both sets of events are passed through gamma-hadron cuts, they are compared.
    These two sets of events were examined for events that disappeared when the pixel was disabled, as well as for {\color{red}new events that appeared (I know what you mean, but be a little more precise like events which failed the cuts in the first but passed in the second.. ?? -Orel)}
    Events that are still present in both event lists can then be tested to see how far their reconstructed position moved in the camera.

    In Figure \ref{fig:dpix_rel_camera}, the relative event rate in the camera is plotted when pixel 115 is disabled in all four telescopes.
    This relative event rate is calculated by taking, {\color{red}for each bin in camera coordinates,  (Bin of what? I guess what you do is reconstruct the position of the shower on the camera and divide those positions into bins? 
This description could be a little clearer. ?? -Orel)}, the number of pixel-disabled reconstructed gamma-like events, divided by the pixel-enabled number of reconstructed events.
    {\color{red}(clean this previous sentence up, it can be much simpler! ??)}
    It can be seen that there is a loss of events near the disabled pixel (the black circle), with a rate closer to 100\% the further away one goes from the disabled pixel.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.8\textwidth]{images/disabled_pixel/relativerate_camera}
      \caption[Relative Event Rate]{
        Event rate in the camera with pixel 115 disabled (denoted by the black circle) in all four telescopes, relative to having all pixels enabled.
        Camera coordinate axes are parallel to azimuth and elevation.
      }
      \label{fig:dpix_rel_camera}
    \end{figure}
    
    While this single-pixel loss-of-events effect was notable, it was not incorporated into the main analysis of this thesis due to the small effect it would have, compared to the amount of work it would take to implement.
    Future analyses may be able to account for these effects in their models of the background rates and effective areas.
    
    {\color{red}You should be a bit more careful how you write paragraph. You can say that the effect was determined to be small for your particular analysis, but you need to back this up with numbers. 
Try to estimate (back of the envelope calculation) what is the fraction of events you lose due to stars in your specific galactic centre observations. Consider that you lose about 5\% of the events in a circle of about 0.3 degrees around a star. So how many stars would you expect which would disable pixels, what is the fraction of events that would fall in that area, etc. 
I am sure that if you do this calculation you can estimate that the effect is much smaller than the statistical/systematic uncertainties and then it is justified to neglect. ?? -Orel}

    In Figure \ref{fig:dpix_disappear}, the positions of events that were rejected by cuts are shown.
    The white area indicates many events are lost in the area of the disabled pixel.
    These events would have smaller images, and would be much more susceptable to being cut.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.8\textwidth]{images/disabled_pixel/disappearing_events}
      \caption[Disappearing Events]{
        Positions of events that disappeared when pixel 115 was disabled in all four telescopes.
        Positions are from their pixel-enabled reconstructed position.
      }
      \label{fig:dpix_disappear}
    \end{figure}

    In Figure \ref{fig:dpix_appear}, the positions of events that are now able to pass cuts are shown.
    It should be noted that these are not events that were 'created' by disabling a pixel.
    Rather, they are events that, with the pixel enabled, did not pass cuts.
    Now that the pixel is disabled, they do pass cuts.

    What is also noticeable is that the highest concentration of lost events was in the pixel's area, whereas the highest rate for appearing events is actually in a ring with a radius of \nicetilde1.5 pixels around the disabled pixel.
    This is probably due to the fact that disabling a pixel can make some images look thinner or wider, depending on where the disabled pixel is in the image.
    A thinner image will look more gamma-like, making it more likely to pass cuts, appearing like 'new' events.
    On the other hand, a wider image looks more hadron-like, and is less likely to pass cuts, causing some events to disappear.

    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.8\textwidth]{images/disabled_pixel/appearing_events}
      \caption[Newly Appearing Events]{
        Positions of new events that appeared when pixel 115 was disabled in all four telescopes.
        Positions are from their pixel-disabled reconstructed position.
      }
      \label{fig:dpix_appear}
    \end{figure}

    In Figure \ref{fig:dpix_move}, the movement of gamma-like events is shown, when pixel 115 was disabled in all four telescopes.
    Only events which moved more than $0.1*\text{psf}$ are shown.
    It should be noted that relatively few ( {\color{red}\nicetilde{}100 in the 20-minute-long run 53703 events} move more than this, and the events that do move are mostly ones with non-compact image shapes that are amputated when a pixel is disabled.
    {\color{red}(How many events are there in a 20 min run? People outside of VERITAS (and me) do not know the event rate so 100 can be 10\% or 0.1\% ??)}
    {\color{red}(Run 53703's datafile was deleted, and I don't have any other crab runs with soft cuts to estimate the event rate for a 20 minute run :(, see /afs/ifh.de/user/n/nkelhos/scratch/Effect\_Of\_Near\_Stars/Pixel\_Off\_Effect for more info ??)}

    {\color{red}(The conclusion in this paragraph is confusing. From the previous paragraph I thought that this effect is actually negligible for VERITAS. But this paragraph talks about effects of pixels halfway across the camera. If it is negligible, state it clearly and say that what is shown in the figure are those rare cases where the effect is noticeable.)}
    What can be learned from this is that while only a small number of events' positions depend on a given pixel, pixels can have an impact on the reconstructed position from halfway across the camera.
    This may imply that the event PSF is, to second order, dependent on the number of disabled pixels {\color{red}(Really? Could the PSF depend on the pixels? I thought it is only an optical effect.)}, though no studies were done to confirm this.


    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.8\textwidth]{images/disabled_pixel/moving_events}
      \caption[Event Movement]{
        Positions of events that moved when pixel 115 (denoted by the red circle) was disabled in all four telescopes.  
        Arrows point from the pixel-enabled position to the pixel-disabled position.
      }
      \label{fig:dpix_move}
    \end{figure}

    As the acceptance for a particular event and the event's effective area are strongly related, the loss of acceptance also means a loss of effective area in the area of this pixel.
    This can have effects on the energy reconstruction.
    Additionally, for CTA and its projected \ang{7}-diameter field of view, more stars will be in the field of view, implying there will be more camera pixels affected by their light.
    
    {\color{red}(There aren't any bright stars or dead pixels in the galactic center data? Tie this back to why this dead pixel study is stil relevant. ??)}
    
    {\color{red}(Again, if I understood correctly that this is negligible, then please preface these two paragraphs by saying that while for VERITAS this effect was found to be negligible, for future experiments like CTA it could be important and then suggest all the ways you think the study can be expanded. Maybe even make it a sub-section in itself. ??)}

    Future studies could also compare how events move in energy when a pixel is disabled.
    Another study might investigate how the reconstructed shower-telescope distance changes, since a shower with fewer pixels will look further away, and may be reconstructed differently.
    In general, as a pixel is disabled, it is expected that lower energy events and showers further away will be more vulnerable, and will show stronger differences than higher energy events or closer showers.


